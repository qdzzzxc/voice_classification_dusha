{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfccs_from_file(file_path, maxlen=None):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "\n",
    "        if len(audio) == 0:\n",
    "            raise ValueError(f\"Input signal length is too small in file: {file_path}\")\n",
    "\n",
    "        if sr != 22050:\n",
    "            audio = librosa.resample(audio, sr, 22050, res_type='kaiser_fast')\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=20)\n",
    "\n",
    "        maxlen = maxlen if maxlen else 256\n",
    "        if mfccs.shape[1] > maxlen:\n",
    "            mfccs = mfccs[:, :maxlen]\n",
    "        elif mfccs.shape[1] < maxlen:\n",
    "            mfccs = np.pad(mfccs, ((0, 0), (0, maxlen - mfccs.shape[1])), mode='constant')\n",
    "\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, offset=0, duration=30)\n",
    "  mfcc = np.array(librosa.feature.mfcc(y=y, sr=sr))\n",
    "  return mfcc\n",
    "\n",
    "def get_melspectrogram(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, offset=0, duration=30)\n",
    "  melspectrogram = np.array(librosa.feature.melspectrogram(y=y, sr=sr))\n",
    "  return melspectrogram\n",
    "\n",
    "def get_chroma_vector(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path)\n",
    "  chroma = np.array(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "  return chroma\n",
    "\n",
    "def get_tonnetz(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path)\n",
    "  tonnetz = np.array(librosa.feature.tonnetz(y=y, sr=sr))\n",
    "  return tonnetz\n",
    "\n",
    "def get_feature(file_path):\n",
    "    mfcc = get_mfcc(file_path)\n",
    "    mfcc_mean = mfcc.mean(axis=1)\n",
    "    mfcc_min = mfcc.min(axis=1)\n",
    "    mfcc_max = mfcc.max(axis=1)\n",
    "    mfcc_feature = np.concatenate( (mfcc_mean, mfcc_min, mfcc_max) )\n",
    "\n",
    "    melspectrogram = get_melspectrogram(file_path)\n",
    "    melspectrogram_mean = melspectrogram.mean(axis=1)\n",
    "    melspectrogram_min = melspectrogram.min(axis=1)\n",
    "    melspectrogram_max = melspectrogram.max(axis=1)\n",
    "    melspectrogram_feature = np.concatenate( (melspectrogram_mean, melspectrogram_min, melspectrogram_max) )\n",
    "\n",
    "    chroma = get_chroma_vector(file_path)\n",
    "    chroma_mean = chroma.mean(axis=1)\n",
    "    chroma_min = chroma.min(axis=1)\n",
    "    chroma_max = chroma.max(axis=1)\n",
    "    chroma_feature = np.concatenate( (chroma_mean, chroma_min, chroma_max) )\n",
    "\n",
    "    tntz = get_tonnetz(file_path)\n",
    "    tntz_mean = tntz.mean(axis=1)\n",
    "    tntz_min = tntz.min(axis=1)\n",
    "    tntz_max = tntz.max(axis=1)\n",
    "    tntz_feature = np.concatenate( (tntz_mean, tntz_min, tntz_max) ) \n",
    "\n",
    "    feature = np.concatenate((chroma_feature, melspectrogram_feature, mfcc_feature, tntz_feature) )\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('crowd_train_without_duplicates.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1806"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29861a60e00f42a4a866ec819e12c3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df.audio_path = df['audio_path'].progress_apply(lambda x: os.path.join('crowd_train', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio_feature'] = df['audio_path'].progress_apply(lambda x: get_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('crowd_train_all_data_embedded.pkl') #в пикл, чтобы np.array не стали строками"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
